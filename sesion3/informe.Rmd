---
title: "MUBD - Estadistica - Sesion 3: Modelo Lineal"
output: github_document
---

Documentación: [MUBD-3.1.Modelo-lineal.pdf](./MUBD-3.1.Modelo-lineal.pdf)

### Table Of Contents

- [Lectura de datos y descriptiva](#lectura-de-datos-y-descriptiva)
  * [1\. Lectura e inspeccion de los datos](#1-lectura-e-inspeccion-de-los-datos)
  * [2\. Explorar todos los pares de datos](#2-explorar-todos-los-pares-de-datos)
  * [3\. Descriptiva bivariante para la variable Cemento](#3-descriptiva-bivariante-para-la-variable-cemento)
  * [4\. Descriptiva bivariante para todas las variables](#4-descriptiva-bivariante-para-todas-las-variables)
- [Generacion de los modelos](#generacion-de-los-modelos)
  * [Modelo 0: Ajuste del Modelo lineal simple](#modelo-0-ajuste-del-modelo-lineal-simple)
  * [Modelo 1: Ajuste del modelo multivariado](#modelo-1-ajuste-del-modelo-multivariado)
  * [Modelo 2: Seleccion automatica de variables del Modelo 1](#modelo-2-seleccion-automatica-de-variables-del-modelo-1)
  * [Modelo 4: Transformaciones polinomicas sobre las predictoras con poly](#modelo-4-transformaciones-polinomicas-sobre-las-predictoras-con-poly)
  * [Modelo 5: Seleccion automatica de caracteristicas del Modelo 4](#modelo-5-seleccion-automatica-de-caracteristicas-del-modelo-4)
  * [Modelo 6: Transformacion BoxCox sobre la respuesta del Modelo 5](#modelo-6-transformacion-boxcox-sobre-la-respuesta-del-modelo-5)
  * [Modelo 7: Quitamos las observaciones influyentes del Modelo 5](#modelo-7-quitamos-las-observaciones-influyentes-del-modelo-5)
  * [Modelo final: Modelo 5](#modelo-final-modelo-5)
- [Testear el modelo final con nuevos datos](#testear-el-modelo-final-con-nuevos-datos)
  * [1\. Volver a hacer las transformaciones](#1-volver-a-hacer-las-transformaciones)
  * [2\. Predicciones para los nuevos valores](#2-predicciones-para-los-nuevos-valores)
  * [3\. Calculo del error y analizar resultados](#3-calculo-del-error-y-analizar-resultados)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Lectura de datos y descriptiva

## 1. Lectura e inspeccion de los datos
```{r echo=FALSE}

setwd('/Users/victorjuez/Google Drive/Documents/Documents academics/MUBD/Estadistica/sesion3')

```
```{r}
datos <- read.table('Concrete_train.txt',sep="\t",header=TRUE)
dim(datos)                  # num filas y columnas
datos[1:5,]                 # ver datos
summary(datos)              # descriptiva de todas las variables 
boxplot(datos, las=2)       # boxplot de todas las variables
```

En este último gráfico vemos como se distribuyen las distintas características.

## 2. Explorar todos los pares de datos
```{r}
pairs(datos) # descriptiva bivariante
```

Con este gráfico, podemos ver como se relacionan todas las características entre ellas una a una. 
De todas ellas nos interesa ver como se relaciona cada una de las características con la variable resultado (Strenght). 
A simple vista, la que parece tener la relación lineal más clara con Strenght es el Cemento (cuando este incrementa, también lo hace la Dureza)

## 3. Descriptiva bivariante para la variable Cemento
```{r}
plot(Strength~Cement,datos)                       # puntos
with(datos,lines(lowess(Strength~Cement),col=2))  # estimacion no parametrica de la relacion
```

Vemos que la relación entre el cemento y la dureza es lineal (línea roja tiene apenas curvatura).

## 4. Descriptiva bivariante para todas las variables
```{r}
par(mfrow=c(2,4))
for(i in 1:8){
  plot(datos$Strength~datos[,i],main=names(datos)[i],xlab=names(datos)[i],ylab="Strength")
  with(datos,lines(lowess(Strength~datos[,i]),col=2))
}
```

Ahora, con todas las otras características, vemos que algunas tinenen curvatura (Age, Water, BlastFurnaceSlag), por ende no presentan una relación lineal.
Y otras sí, como el superplasticizer o el CoarseAggregate

# Generacion de los modelos

## Modelo 0: Ajuste del Modelo lineal simple
Vamos a generar un modelo que explique únicamente como el Cemento afecta a la Dureza, descartando el resto de características.

```{r}
mod.lm0 <- lm(Strength~Cement,datos)
summary(mod.lm0)
```

- **Residuals**: descriptiva de los residuos (errores). 
- **Coeficientes**:
  - *Estimate*: coeficientes del término independiente (intercept) y el cemento. Por cada unidad de cemento que yo agrego, la dureza augmenta en 0.08 uds.
  - *Std. Error*: Error estándar de la estimación, en el caso del Cemento, estimamos un valor de 0,08 pero con un error de +- 0.005
  - *t value*: Es la relación que hay entre la Estimación y el Std. Error (Estimación/Error). Nos interesa que sea lo mayor posible, lo que signfica que hay un error pequeño
  - *Pr(>|t|)*: P-valor de los coeficientes. Utiliza el t-valor para calcularlo. Un valor muy pequeño de este (< 0.05) implica que descartamos la hipótesis nula, es decir, que el coeficiente sea 0. Dicho de otra forma, en el caso del cemento, implica que éste está influyendo sobre la variable respuesta (Dureza). Estamos seguros que no es un coeficiente igual a 0, lo que por contra, significaría que el cemento no tiene ningún impacto sobre la Dureza (por cada unidad de cemento que agrego, la dureza varia +- 0) y por tanto no deberíamos utilizarla como característica del modelo.
- **Signif. codes**: el R nos ayuda y directamente nos califica cada coeficiente según si son más o menos significativos: `0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1`.
  - p-valor entre (0 y 0.001): `***`
  - p-valor entre (0.001 y 0.01): `**`,
  - p-valor entre (0.01 y 0.05): `*`,
  - p-valor entre (0.05 y 0.1): `.`,
  - p-valor entre (0.1 y 1): ` `
- **Residual standard error**: Como la media de los residuos, es lo que yo espero equivocarme utilizando el modelo.
- **Multiple R-squared**: $R^2$ Es el porcentaje de variabilidad que explica el modelo. Cerca de 0 no explica nada, cerca del 1 explica mucho. En este caso, considerando que tenemos una única variable (Cemento), un valor de 0.25 está bastante bien, podemos explicar un 25% de la dureza utilizando el cemento. 
- **F-static**: si el modelo en general explica algo o no.

```{r}
par(mfrow=c(1,1))
plot(Strength~Cement,datos)
abline(mod.lm0,col="red")
```

- En este gráfico vemos como el modelo explica la Dureza en función del Cemento.
- Comparándolo con el [resultado real](#3-descriptiva-bivariante-para-la-variable-cemento) vemos que el modelo está bastante bien.

## Modelo 1: Ajuste del modelo multivariado
Ahora vamos a generar un modelo utilizando todas las características.
```{r}
mod.lm1 <- lm(Strength~Cement + BlastFurnaceSlag + FlyAsh +      
                       Water + Superplasticizer + CoarseAggregate +
                       FineAggregate + Age,datos)                   # Ajuste del modelo
# mod.lm1 <- lm(Strength~.,datos)                                     # Instruccion equivalente a la anterior
mod.lm1                                                             # Ver coeficientes
summary(mod.lm1)                                                    # Resumen del modelo
```

- Análisis rápido de la estimación: por cada unidad de cemento que agreguemos, la dureza augmentará 0.125. En cambio, por cada unidad de agua que agreguemos, la dureza se reducirá en 0.13
- A simple vista ya vemos las variables más significativas, con tres estrellas (Cemento, FlyAsh, Age..) y las menos (FineAggregate, CoarseAggregate).
- Importante destacar el R-squared: ha augmentado considerablemente (0.6253) en comparación al 0.25 que teníamos en el modelo anterior con solo el Cemento como variable. esto nos indica que ahora con este modelo que contiene todas las variables podemos explicar un 63% la dureza.

## Modelo 2: Seleccion automatica de variables del Modelo 1

```{r}
mod.lm2 <- step(mod.lm1)                   # Seleccionar variables
```

- **AIC** (Akaike Information Criteria): Cuanto más pequeño es su valor, mejor. El indicador será más pequeño cuando menos variables se utilicen en el modelo y más verosimil sea (bien ajustado).
- En la tabla anterior observamos el AIC resultante por cada variable que quitamos al modelo. En este caso, si NO quitamos ninguna, tenemos el valor más pequeño del AIC, que es lo que buscamos.


```{r}
summary(mod.lm2)                           # Modelo con variables seleccionadas
```

Al no quitar ninguna variable, tenemos el mismo modelo que el anterior (lm1)

### Validacion de las premisas del Modelo 2
Premisas:

- **Linealidad**: Una recta/plano/hiperplano se ajusta bien a los datos. Los residuos deben distribuirse uniformemente por encima y por debajo
del cero a lo largo de los valores predichos.
- **Homocedasticidad**: Variabilidad constante. Los residuos deben distanciarse del cero lo mismo a lo largo de los
valores predichos (no tener forma de embudo).
- **Normalidad de los residuos**: Los errores son normales. Los residuos deben ajustarse a la recta de Normalidad.
- **Independencia**: La muestra es aleatoria simple y el resultado de una observación no condiciona el resto.

```{r}
par(mfrow=c(2,2))                          # ventana para 4 gr?ficos
plot(mod.lm2)                              # graficos para valorar premisas
```

- **Linealidad**: Se cumple poco. (Residuals vs Fitted) vemos que los residuos no acaban de distribuirse de forma uniforme por encima y por debajo del cero a lo largo de los valores predichos, causando una curvatura en la media, por lo que no es lineal.
- **Homocedasticidad**: No se cumple. (Residuals vs Fitted)  Tiene un poco forma de embudo, en valores predichos menores los residuos están más concentrados en el 0 y cuando son valores más grandes, la dispersión de residuos augmenta.
- **Normalidad de los residuos**: Se cumple. (Normal Q-Q). Los residuos se ajustan bastante bien a la recta de Normalidad.
- **Independencia**: Suponemos que se cumple. (Depende del buen diseño de la recogida de datos).

Cómo interpretar los gráficos:

- **Residuals vs Fitted**: Nos indica la Homocedasticidad y la Linealidad. 
  - Linealidad: Se cumple si la línea roja es horizontal y se mantiene constante a lo largo de los valores estimados.
  - Homocedasticidad: Se cumple si los residuos se distancian del cero lo mismo a lo largo de los valores predichos (no tener forma de embudo).
- [**Scale-Location**](https://boostedml.com/2019/03/linear-regression-plots-scale-location-plot.html): Nos da la misma información que el anterior pero de forma más clara. Ya que normaliza los residuos y éstos son solo positivos.
- [**Residuals vs Leverage**](https://boostedml.com/2019/03/linear-regression-plots-residuals-vs-leverage.html): Nos indica la Homocedasticidad y si hay puntos de gran influencia. 
  - Este gráfico nos sirve para ver como cambia la dispersión de los residuos estandarizados segun el [leverage](https://en.wikipedia.org/wiki/Leverage_(statistics)) (nivel de palanca).
  - Homocedasticidad: La dispersión de los residuos estandarizados no debería cambiar a lo largo de los valores del leverage. En este último caso disminuye, lo que indica Homocedasticidad.
  - Puntos de gran influencia: Debemos fijarnos el la línea de Cook (línea roja discontínua). Todos los valores fuera de esta línea son puntos de **gran influencia**. Los puntos de gran influencia tienen mucha influencia en el modelo por lo que eliminarlos haría mejorarlo. En este último caso, vemos que no hay ningun punto fuera de la línea (de hecho la línea no llega ni a aparecer en el gráfico) y no se detectan puntos de influencia. 


### Nueva descriptiva: Residuos vs variables predictoras
Hay que mejorar las premisas del modelo anterior, y empezamos analizando las variables predictoras para ver si hay que transformarlas.

```{r}
library(car)
residualPlots(mod.lm2)
```

- Solo los residuos de las características Cemento, FineAggregate y FlyAsh son mínimamente lineales, pero las otras presentan mucha curvatura.
- Tendremos que aplicar transformaciones a estas características predictoras para linealizarlas.

## Modelo 4: Transformaciones polinomicas sobre las predictoras con poly
Con poly: que se incluyen términos polinómicos de orden mayor

```{r}
mod.lm4 <- lm(Strength ~ poly(Cement,2) + poly(BlastFurnaceSlag,2) + poly(FlyAsh,2)+
                         poly(Water,2) + poly(Superplasticizer,2) + CoarseAggregate +
                         poly(FineAggregate,2) + poly(Age,2),datos) # generamos el nuevo modelo con las transformaciones
summary(mod.lm4)
```

- Vemos todos los coeficientes de todas las características aplicando transformaciones polinómicas de 1er y 2o grado y la significancia de cada una de ellas. A excepción del 'CoarseAggregate', que como habíamos observado anteriormente ya seguía una forma lineal y no requería de transformación. 
- Por otro lado, vemos que el error estándar ha disminuido (7.92 vs 10.0) en el [Modelo 2](#modelo-2-seleccion-automatica-de-variables-del-modelo-1), y que el R-squared ha augmentado (0.7798 vs 0.6253), por lo que ahora podemos explicar un 0.7798 de la dureza con este modelo. En general, hemos obtenido una mejora sustancial respecto respecto al modelo anterior únicamente transformando las variables predictoras.

## Modelo 5: Seleccion automatica de caracteristicas del Modelo 4
Seleccionamos automáticamente las características a utilizar del [Modelo 4](#modelo-4-transformaciones-polinomicas-sobre-las-predictoras-con-poly)

```{r}
mod.lm5 <- step(mod.lm4) # Seleccion automatica de caracteristicas
```

Vemos que lo que da mejor resultado es eliminar el CoarseAggregate, ya que aparece el primero de la lista y el AIC resultante tras su eleminación es el menor de todos (2912.9), respecto (1214.9) si no elimináramos ninguna.

```{r}
summary(mod.lm5) # Descriptiva del modelo
```

Tras eliminar el CoarseAggregate y hacer la descriptiva del modelo, podemos observar que el resultado no varia significativamente respecto el [Modelo 4](#modelo-4-transformaciones-polinomicas-sobre-las-predictoras-con-poly). El multiple R-squared se mantiene igual y solo disminuye muy levemente el error estándar.

### Colinealidad
Para analizar la colinealidad de las variables (qué tan relacionadas estan entre si) utilizamos el VIF: 

- Por orden general, un VIF mayor que 5 u 8 es un valor muy grande que nos indica que hay una relación entre las características, es decir, que las características en cuestión nos explican lo mismo, por lo que no tiene sentido tenerlas juntas en el modelo.
- Buscamos un VIF menor a 5.

```{r}
vif(mod.lm5)
```

### Validacion
```{r}
par(mfrow=c(2,2))
plot(mod.lm5) # Validación de las premisas
```

- **Linealidad**: Se cumple. (Residuals vs Fitted) vemos que los residuos se distribuyen uniformemente por encima y por debajo del cero a lo largo de los valores predichos. Se ve claramente con la línea roja recta en el 0.
- **Homocedasticidad**: No se cumple. (Residuals vs Fitted) En comparación al [Modelo 2](#modelo-2-seleccion-automatica-de-variables-del-modelo-1), la Homocedesticidad ha mejorado un poco, pero seguimos teniendo un poco forma de embudo (residuos más concentrados en valores predichos pequeños y más dispersos en valores predichos grandes)
- **Normalidad de los residuos**: Se cumple. (Normal Q-Q). Los residuos se ajustan bastante bien a la recta de Normalidad
- **Independencia**: Suponemos que se cumple. (Depende del buen diseño de la recogida de datos)


```{r}
residualPlots(mod.lm5)
```

Comparamos con las [características del modelo 2](#nueva-descriptiva-residuos-vs-variables-predictoras) y vemos que:

- Se han linealizado correctamente todas ellas, ya no hay presencia de curvaturas.
- Aun así hay Homocedasticidad, ya que en diversas características los residuos no estan distribuidos uniformemente (Age, Superplasticizer)

## Modelo 6: Transformacion BoxCox sobre la respuesta del Modelo 5
Transformamos ahora las estimaciones para ver si podemos mejorar aun más el modelo.

### 1. Buscamos la lambda optima

```{r}
par(mfrow=c(1,1))
bc <- boxCox(mod.lm5)
bc$x[which.max(bc$y)] #lambda optima la cual vamos a elevar las variables resultado (dureza) a esta lambda 
```

### 2. Transformamos las variables resultado y analizamos el modelo resultante

```{r}
lamb <- bc$x[which.max(bc$y)]  
datos$Strength2 <- datos$Strength^lamb
mod.lm6 <- lm(Strength2~poly(Cement,2) + poly(BlastFurnaceSlag,2) + poly(FlyAsh,2) +
                        poly(Water,2) + poly(Superplasticizer,2) +
                        poly(FineAggregate,2) + poly(Age,2), datos)
summary(mod.lm6)
```

Comparamos otra vez con los modelos anteriores y vemos:

- El error estándar a disminuido de 7.787 en el [Modelo 5](#validacion) vs 1.596 ahora
- El multiple R-squared ha augmentado muy levemente: 0.7798 vs 0.7824 ahora

### 3. Validacion del modelo

```{r}
par(mfrow=c(2,2))
plot(mod.lm6)
```

- Vemos que corregimos los problemas de normalidad, pero que seguimos teniendo Homocedasticidad.
- Nos quedaríamos con el [modelo 5](#validacion), que es mas simple y no deteriora ninguna premisa. A parte de que la R2 se mantiene prácticamente igual.

## Modelo 7: Quitamos las observaciones influyentes del Modelo 5

### 1. Detectar los puntos influyentes

```{r}
influenceIndexPlot(mod.lm5) 
```

- **Cook's distance**: Vemos que hay dos observaciones con gran influencia a posteriori (81 y 147).
- **Residuals**: Una observación, para estar bien explicada por el modelo, debería tener un residuo entre -2 y 2 aproximádamente. En el diagrama vemos que la observación 248 tiene un residuo de 4. es decir, muy mal explicada por el modelo.
- **P-valor**: Coincidiendo con la observación anterior (248), vemos que ésta observación tiene un p-valor menor que 0.5, en concreto 0.2, lo que implica que lo descartamos.
- **Hat-values**: Las observaciones 81 y 65 tienen mucha influencia a priori.

- [**Cook's distance vs Hat-values**](https://stats.stackexchange.com/questions/319024/cooks-distance-vs-hat-values): 
  - **Hat-values**: Nos indica las observaciones con más palanca. En otras palabras, las observaciones que se distancian más de su valor real. En el resultado anterior, vemos que los resultados de las observaciones 65 y 81 se alejan mucho de los valores reales.
  - **Cook's distance**: Muestra cómo cambiaría el modelo si elmináramos una determinada observación. A mayor distancia, más efecto tendrá eliminarlos del modelo. Nos referimos a este tipo de influencia como a posteriori porque nos indica como cambiará el resultado si quitamos dichas observaciones (post-resultado). Por otro lado, los **hat-values** sólo nos indica aquellos puntos con gran palanca, sin saber qué efecto tiene quitarlos del modelo (pre-resultado).


```{r}
par(mfrow=c(1,1))
influencePlot(mod.lm5)  
```


### 2. Eliminar los influyentes del modelo

Eliminamos los puntos 81, 147 y 248, que corresponden a los valores detectados en el gráfico de la distancia de Cook y del p-valor.

```{r}              
obs.rm <- c(81,147,248)                              # Eliminar las 2 mas influyentes a posteriori (81 y 147) y la peor explicada (248)
col.points <- rep(rgb(0,0,0,0.1),nrow(datos))        # Vector de colores
col.points[obs.rm] <- 2:4                            # Colores distintos para las observaciones influyentes
pairs(datos[,-10],col=col.points,pch=19,cex=0.8)     # Dibujo por pares de las observaciones influyentes
```

Este plot nos muestra donde se encuentran los puntos influyentes seleccionados en los distintos gráficos que relacionan las características entre sí.

### 3. Ajuste del modelo sin observaciones influyentes

```{r}
datos.rm <- datos[-obs.rm ,]  # Nos creamos un nuevo data.frame sin estas observaciones
mod.lm7 <- lm(Strength~poly(Cement,2) + poly(BlastFurnaceSlag,2) + poly(FlyAsh,2)+
                       poly(Water,2) + poly(Superplasticizer,2)  +
                       poly(FineAggregate,2) + poly(Age,2),datos.rm)
```

### 4. Comparar con el Modelo 5

```{r}
summary(mod.lm7)   # Modelo nuevo sin outliers y observaciones influyentes
summary(mod.lm5)   # Modelo antiguo
```

Finalmente, es tan insignificante la mejora que obtenemos con el nuevo modelo (multiple R-squared 0.7857 en el nuevo vs 0.7798 en el antiguo) que nos quedamos con el antiguo. Menos transformaciones necesarias mejor.

## Modelo final: Modelo 5

```{r, fig.width=10, fig.height=10}
##-- Modelo final
mod.final <- mod.lm5

##-- Efectos
library('effects')
plot(allEffects(mod.final))
```

# Testear el modelo final con nuevos datos

## 1. Volver a hacer las transformaciones
```{r}
# setwd('...')
test <- read.table('Concrete_test.txt',sep="\t",header=TRUE)

##-- Volver a hacer transformaciones en test (por si la necesito)
test$Strength2 <- test$Strength^lamb
```

## 2. Predicciones para los nuevos valores

```{r}
##-- Predicciones
pr <- predict(mod.final,test)   # Predicciones para los nuevos valores
par(mfrow=c(1,1))           
plot(pr,test$Strength,asp=1)    # Predicciones vs valores predichos 
abline(0,1,col=2,lwd=2)         # Bisectriz
```

Valores reales vs valores predichos. Buen resultado, bastante ajustado.

## 3. Calculo del error y analizar resultados
```{r}
##--EQM (Error Cuadratico Medio)
n <- dim(test)[1]                                       # Tamanyo muestral
## vemos que es un 30% de la muestra de entrenamiento
EQM <- sum((pr-test$Strength)^2)/n                      # Error Cuadratico Medio
sqrt(EQM)                                               # Incertidumbre a posteriori                                                
```

Arriba: Incertidumbre a posteriori

```{r}
sd(test$Strength)                                       # Incertidumbre a priori --> El modelo me reduce a la mitad la incertidumbre en las predicciones
```

Arriba: Incertidumbre a priori, el modelo me reduce a la mitad la incertidumbre en las predicciones

```{r}
summary(test$Strength)
```

En un rango de 80, tener un error de 8 está bastante bien.