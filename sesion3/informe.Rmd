---
title: "MUBD - Estadistica - Sesion 3: Modelo Lineal"
output: github_document
---

Documentación: [MUBD-3.1.Modelo-lineal.pdf](./MUBD-3.1.Modelo-lineal.pdf)

### Table Of Contents

- [Lectura de datos y descriptiva](#lectura-de-datos-y-descriptiva)
  * [1\. Lectura e inspeccion de los datos](#1-lectura-e-inspeccion-de-los-datos)
  * [2\. Explorar todos los pares de datos](#2-explorar-todos-los-pares-de-datos)
  * [3\. Descriptiva bivariante para la variable Cemento](#3-descriptiva-bivariante-para-la-variable-cemento)
  * [4\. Descriptiva bivariante para todas las variables](#4-descriptiva-bivariante-para-todas-las-variables)
- [Generacion de los modelos](#generacion-de-los-modelos)
  * [Modelo 0: Ajuste del Modelo lineal simple](#modelo-0-ajuste-del-modelo-lineal-simple)
  * [Modelo 1: Ajuste del modelo multivariado](#modelo-1-ajuste-del-modelo-multivariado)
  * [Modelo 2: Seleccion automatica de variables del Modelo 1](#modelo-2-seleccion-automatica-de-variables-del-modelo-1)
  * [Modelo 4: Transformaciones polinomicas sobre las predictoras con poly](#modelo-4-transformaciones-polinomicas-sobre-las-predictoras-con-poly)
  * [Modelo 5: Seleccion automatica de caracteristicas del Modelo 4](#modelo-5-seleccion-automatica-de-caracteristicas-del-modelo-4)
  * [Modelo 6: Transformacion BoxCox sobre la respuesta del Modelo 5](#modelo-6-transformacion-boxcox-sobre-la-respuesta-del-modelo-5)
  * [Modelo 7: Quitamos las observaciones influyentes del Modelo 5](#modelo-7-quitamos-las-observaciones-influyentes-del-modelo-5)
  * [Modelo final: Modelo 5](#modelo-final-modelo-5)
- [Testear el modelo final con nuevos datos](#testear-el-modelo-final-con-nuevos-datos)
  * [1\. Volver a hacer las transformaciones](#1-volver-a-hacer-las-transformaciones)
  * [2\. Predicciones para los nuevos valores](#2-predicciones-para-los-nuevos-valores)
  * [3\. Calculo del error y analizar resultados](#3-calculo-del-error-y-analizar-resultados)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Lectura de datos y descriptiva

## 1. Lectura e inspeccion de los datos
```{r echo=FALSE}

setwd('/Users/victorjuez/Google Drive/Documents/Documents academics/MUBD/Estadistica/sesion3')

```
```{r}
datos <- read.table('Concrete_train.txt',sep="\t",header=TRUE)
dim(datos)                  # num filas y columnas
datos[1:5,]                 # ver datos
summary(datos)              # descriptiva de todas las variables 
boxplot(datos, las=2)       # boxplot de todas las variables
```

En este último gráfico vemos como se distribuyen las distintas características. Podemos observar como algunas lo hacen de forma normal (Cement, CoarseAggregate, FineAggregate). Y otras no (FlyAsh, Age, Superplasticizer). Posteriormente veremos diferentes filtros para intentar normalizarlas todas.

## 2. Explorar todos los pares de datos
```{r}
pairs(datos) # descriptiva bivariante
```

Con este gráfico, podemos ver como se relacionan todas las características entre ellas una a una. 
De todas ellas nos interesa ver como se relaciona cada una de las características con la variable resultado (Strenght). 
A simple vista, la que parece tener la relación lineal más clara con Strenght es el Cemento (cuando este incrementa, también lo hace la Dureza)

## 3. Descriptiva bivariante para la variable Cemento
```{r}
plot(Strength~Cement,datos)                       # puntos
with(datos,lines(lowess(Strength~Cement),col=2))  # estimacion no parametrica de la relacion
```

Con esta estimación (linea roja), afirmamos pues, que la relación es lineal

## 4. Descriptiva bivariante para todas las variables
```{r}
par(mfrow=c(2,4))
for(i in 1:8){
  plot(datos$Strength~datos[,i],main=names(datos)[i],xlab=names(datos)[i],ylab="Strength")
  with(datos,lines(lowess(Strength~datos[,i]),col=2))
}
```

Ahora, con todas las otras características, vemos que algunas tinenen curvatura (Age, Water, BlastFurnaceSlag), por ende no presentan una relación lineal.
Y otras sí, como el superplasticizer o el CoarseAggregate

# Generacion de los modelos

## Modelo 0: Ajuste del Modelo lineal simple
```{r}
mod.lm0 <- lm(Strength~Cement,datos)
summary(mod.lm0)
```

- **Residuals**: descriptiva de los residuos (errores). 
- **Coeficientes**:
  - *Estimate*: coeficientes del termino independiente (intercept) y el cemento. Por cada unidad de cemento que yo agrego, la dureza augmenta en 0.08 uds.
  - *Std. Error*: Error estándar de la estimación, en el caso del Cemento, estimamos un valor de 0,08 pero con un error de +- 0.005
  - *t value*: Es la relación que hay entre la Estimación y el Std. Error (Estimación/Error). Nos interesa que sea lo mayor posible, lo que signfica que hay un error pequeno
  - *Pr(>|t|)*: P-valor de los coeficientes. Utiliza el t-valor para hacerlo. Un valor muy pequeno de este (< 0.05) implica que descartamos la hipótesis nula, es decir, que el coeficiente sea 0. Dicho de otra forma, en el caso del cemento, implica que éste está influyendo sobre la variable respuesta (Dureza). Nos aseguramos que no es un coeficiente igual a 0, lo que por contra, significaría que el cemento no tiene ningún impacto sobre la Dureza (por cada unidad de cemento que agrego, la dureza varia +- 0) y por tanto no deberíamos utilizarla como característica del modelo.
- **Signif. codes**: el R nos ayuda y directamente nos califica cada coeficiente según si son más o menos significativos: `0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1`.
  - p-valor entre (0 y 0.001): `***`
  - p-valor entre (0.001 y 0.01): `**`,
  - p-valor entre (0.01 y 0.05): `*`,
  - p-valor entre (0.05 y 0.1): `.`,
  - p-valor entre (0.1 y 1): ` `
- **Residual standard error**: Como la media de los residuos, lo que espero equivocarme utilizando el modelo
- **Multiple R-squared**: $R^2$ Es el porcentaje de variabilidad que explica el modelo. Cerca de 0 no explica nada, cerca del 1 explica mucho. En este caso, considerando que tenemos una única variable (Cemento), un valor de 0.25 está bastante bien, podemos explicar un 25% de la dureza utilizando el cemento. 
- **F-static**: si el modelo en general explica algo o no

```{r}
par(mfrow=c(1,1))
plot(Strength~Cement,datos)
abline(mod.lm0,col="red")
```

La línea roja es el modelo lineal 

## Modelo 1: Ajuste del modelo multivariado

```{r}
mod.lm1 <- lm(Strength~Cement + BlastFurnaceSlag + FlyAsh +      
                       Water + Superplasticizer + CoarseAggregate +
                       FineAggregate + Age,datos)                   # Ajuste del modelo
# mod.lm1 <- lm(Strength~.,datos)                                     # Instruccion equivalente a la anterior
mod.lm1                                                             # Ver coeficientes
summary(mod.lm1)                                                    # Resumen del modelo
```

- Análisis rápido de la estimación: por cada unidad de cemento que agreguemos, la dureza augmentará 0.125. En cambio, por cada unidad de agua que agreguemos, la dureza se reducirá en 0.13
- A simple vista ya vemos las variables más significativas, con tres estrellas (Cemento, FlyAsh, Age..) y las menos (FineAggregate, CoarseAggregate).
- Importante destacar el R-squared: ha augmentado considerablemente (0.6253) en comparación al 0.25 que teníamos en el modelo anterior con solo el Cemento como variable. Ésto nos indica que ahora con éste modelo que contiene todas las variables podemos explicar un 63% la dureza

## Modelo 2: Seleccion automatica de variables del Modelo 1

```{r}
mod.lm2 <- step(mod.lm1)                   # Seleccionar variables
```

- AIC: Se mira qué bueno es el modelo y por otra parte el numero de parámetros que tiene el modelo. Nos interesa que el modelo sea lo más bueno posible (verosimilitud) con el mínimo de variables posibles. Cuanto más pequeno es el AIC mejor.
- En la tabla anterior observamos el AIC resultante por cada variable que quitamos al modelo. En este caso, si NO quitamos ninguna, tenemos el valor más pequeno del AIC, que es lo que buscamos.


```{r}
summary(mod.lm2)                           # Modelo con variables seleccionadas
```

Al no quitar ninguna variable, tenemos el mismo modelo que el anterior (lm1)

### Validacion de las premisas del Modelo 2
Premisas:
- **Linealidad**: Una recta/plano/hiperplano se ajusta bien a los datos
- **Homoscedasticidad**: Variabilidad constante
- **Normalidad de los residuos**: Los errores son normales
- **Independencia**: La muestra es aleatoria simple y el resultado de una observación no condiciona el resto

```{r}
par(mfrow=c(2,2))                          # ventana para 4 gr?ficos
plot(mod.lm2)                              # graficos para valorar premisas
```

- **Residuals vs Fitted**: Nos indica la Homoscedasticidad, para cumplirla, los residuos, deberían distribuirse de la misma forma por todo el rango de los 'Fitted values' (estimaciones). Así pues, vemos que no es el caso, ya que cuando éstos son pequenos, los residuos oscilan menos (muy cercanos a la linea roja). Y en cambio cuando mayor son los las estimaciones, más dispersos son los residuos
- **Scale-Location**: Con el mismo propósito que el anterior, pero estandarizando los residuos, de forma que estos son todos positivos. (Es como si plegaramos el diagrama anterior por la mitad). Con esto, nos podemos fijar en la línea roja, y en este caso observar que tiene una tendencia decreciente, es decir, que cuando mayor es la estimación más grande es el residuo (más error tenemos).
- **Normal Q-Q**: Nos sirve para ver si el las estimaciones estan distribuidos de forma normal o no. En este caso vemos que a excepción de valores muy pequenos y grandes sí que lo hacen.
- [**Residuals vs Leverage**](https://boostedml.com/2019/03/linear-regression-plots-residuals-vs-leverage.html): Este gráfico nos sirve para ver como cambia la dispersión de los residuos estandarizados cuando el [leverage](https://en.wikipedia.org/wiki/Leverage_(statistics)) (puntos de influencia) incrementan. La dispersión de los residuos estandarizados no deberían cambiar cuando los puntos de influencia augmentan (nos estamos fijando en los puntos negros): en este caso parece que disminuye, lo que indica homoscedesticidad.
  - Por otro lado los puntos con un gran 'leverage' (palanca) son puntos de **gran influencia**, por lo que eliminarlos harían cambiar mucho el modelo. Para este propósito nos fijamos en la línea de Cook (la cual mesura el efecto de eliminar el valor). Todos los puntos fuera de ésta línea indican que tienen una gran influencia. En este caso vemos que no hay ninguno que esté furea la línea de Cook (de hecho la línea no llega ni a aparecer en el diagrama).


### Nueva descriptiva: Residuos vs variables predictoras
```{r}
library(car)
residualPlots(mod.lm2)
```

- Aquí podemos observar por cada característica como varia la dispersión de los residuos. Lo que buscamos, otra vez, es que ésta no varie a lo largo de los valores de cada característica. Como vemos, las características que lo cumplen son: Cement, CoarseAggregate y Water. En las otras, en cambio, observamos curvaturas lo cual indican justamente lo contrario.
- Tendremos que aplicar transformaciones a éstas características para linealizarlas

## Modelo 4: Transformaciones polinomicas sobre las predictoras con poly
Con poly: que se incluyen términos polinómicos de orden mayor

```{r}
mod.lm4 <- lm(Strength ~ poly(Cement,2) + poly(BlastFurnaceSlag,2) + poly(FlyAsh,2)+
                         poly(Water,2) + poly(Superplasticizer,2) + CoarseAggregate +
                         poly(FineAggregate,2) + poly(Age,2),datos) # generamos el nuevo modelo con las transformaciones
summary(mod.lm4)
```

- Vemos todos los coeficientes de todas las características aplicando transformaciones polinomicas de 1er y 2o grado y la significancia de cada una de ellas. A excepción del 'CoarseAggregate', que como habiamos observado anteriormente ya seguía una forma lineal y no requeria de transformación. 
- Por otro lado, vemos que el error estándar ha disminuido (7.92 vs 10.0) en el modelo anterior, y que el R-squared ha augmentado (0.7798 vs 0.6253), por lo que ahora podemos explicar un 0.7798 de la dureza con este modelo. En general, hemos obtenido una mejora sustancial respecto respecto al modelo anterior únicamente transformando las variables predictoras.

## Modelo 5: Seleccion automatica de caracteristicas del Modelo 4
Seleccionamos automáticamente las características a utilizar del modelo anterior (lm4)

```{r}
mod.lm5 <- step(mod.lm4) # Seleccion automatica de caracteristicas
```

Vemos que lo que da mejor resultado es elminiar el CoarseAggregate, ya que aparece el primero de la lista y el AIC resultante tras su eleminación es el menor de todos (2912.9), respecto (1214.9) si no elimináramos ninguna.

```{r}
summary(mod.lm5) # Descriptiva del modelo
```

Tras eliminar el CoarseAggregate y hacer la descriptiva del modelo, podemos observar que el resultado no varia significativamente respecto el modelo anterior (lm4). El multipple R-squared se mantiene igual y solo disminuye muy levemente el error estándar.

### Colinealidad
Para analizar la colinealidad de las variables (qué tan relacionadas estan entre si) utilizamos el VIF: 

- Por orden general, un VIF mayor que 5 u 8 es un valor muy grande que nos indica que hay una relación entre las características, es decir, que las características en cuestión nos explican lo mismo, por lo que no tiene sentido tenerlas juntas en el modelo.
- Por contra, un VIF menor a 5 nos indica que las variables predictoras no estan muy relacionadas entre si. Es lo que buscamos.

```{r}
vif(mod.lm5)
```

### Validacion
```{r}
par(mfrow=c(2,2))
plot(mod.lm5) # Validación de las premisas
```

- **Linealidad**: Se cumple. (Residuals vs Fitted) vemos que los residuos se distribuyen uniformemente por encima y por debajo del cero a lo largo de los valores predichos. Se ve claramente con la línea roja recta en el 0.
- **Homocedasticidad**: Se cumple. (Residuals vs Fitted) En comparación al modelo lm2, la homoscedesticidad ha mejorado un poco, ahora vemos una mejor distribución de los residuales a lo largo de las estimaciones, aunque seguimos teniendo un poco forma de embudo (residuos más concentrados en valores predichos pequenos y más dispersos en valores predichos grandes)
- **Normalidad de los residuos**: Se cumple. (Normal Q-Q). Los residuos se ajustan bastante bien a la recta de Normalidad
- **Independencia**: Suponemos que se cumple. (Depende del buen diseño de la recogida de datos)


```{r}
residualPlots(mod.lm5)
```

- En el plot de arriba tenemos el gráfico (Residuals vs Fitted) para cada característica por separado.
- Vemos que todas cumplen la premisa de Linealidad, pero no la de Homocedasticidad, ya que en diversas características los residuos no estan distribuidos uniformemente (Age, Superplasticizer)
- Aun así, las premisas más importantes son las del modelo completo, con todas las características, analizadas anteriormente y validadas.

## Modelo 6: Transformacion BoxCox sobre la respuesta del Modelo 5
Transformamos ahora las estimaciones para ver si podemos mejorar aun más el modelo.

### 1. Buscamos la lambda optima

```{r}
par(mfrow=c(1,1))
bc <- boxCox(mod.lm5)
bc$x[which.max(bc$y)] #lambda optima la cual vamos a elevar las variables resultado (dureza) a esta lambda 
```

### 2. Transformamos las variables resultado y analizamos el modelo resultante

```{r}
lamb <- bc$x[which.max(bc$y)]  
datos$Strength2 <- datos$Strength^lamb
mod.lm6 <- lm(Strength2~poly(Cement,2) + poly(BlastFurnaceSlag,2) + poly(FlyAsh,2) +
                        poly(Water,2) + poly(Superplasticizer,2) +
                        poly(FineAggregate,2) + poly(Age,2), datos)
summary(mod.lm6)
```

Comparamos otra vez con los modelos anteriores y vemos:

- El error estándar a disminuido de 7.792 en el lm4 vs 1.596 ahora
- El multiple R-squared ha augmentado muy levemente: 0.7798 vs 0.7824 ahora

### 3. Validacion del modelo

```{r}
par(mfrow=c(2,2))
plot(mod.lm6)
```

- Vemos que corregimos los problemas de normalidad, pero que seguimos teniendo parabola homesteicedad
- Nos quedariamos con el modelo 5, que es mas simple y no deteriora ninguna premisa. A parte de que la R2 se mantiene practicamente igual.

## Modelo 7: Quitamos las observaciones influyentes del Modelo 5

### 1. Detectar los puntos influyentes

```{r}
influenceIndexPlot(mod.lm5) 
```

- **Cook's distance**: Vemos que hay dos observaciones con gran influencia a posteriori (81 y 147).
- **Residuals**: Una observación, para estar bien explicada por el modelo, debería tener un residuo entre -2 y 2 aproximadamente. En el diagrama vemos que la observacion 248 tiene un residuo de 4. es decir, muy mal explicada por el modelo.
- **P-valor**: Coincidiendo con la observacion anterior (248), vemos que ésta observación tiene un p-valor menor que 0.5, en concreto 0.2, lo que implica que lo descartamos.
- **Hat-values**: Las observaciones 81 y 65 tienen mucha influencia a priori.

- [**Cook's distance vs Hat-values**](https://stats.stackexchange.com/questions/319024/cooks-distance-vs-hat-values): 
  - **Hat-values**: Nos indica las observaciones con más palanca. En otras palabras, las observaciones que se distancian más de su valor real. En el resultado anterior, vemos que los resultados de las observaciones 65 y 81 se alejan mucho de los valores reales.
  - **Cook's distance**: Muestra cómo cambiaría el modelo si elmináramos una determinada observación. Es decir, si tendría un gran efecto o no eliminar dichos puntos del modelo. Nos referimos a éste tipo de influencia como a posteriori porque nos indica como cambiará el resultado si quitamos dichas observaciones (post-resultado). Por otro lado, los **hat-values** sólo nos indica aquellos puntos con gran palanca, sin saber qué efecto tiene quitarlos del modelo (pre-resultado).


```{r}
par(mfrow=c(1,1))
influencePlot(mod.lm5)  
```

Gráfico de los Hat-Values, se ve claramente cómo los valores 81 y 65 son los más influyentes (a priori).

### 2. Eliminar los influyentes del modelo

**No estoy seguro de esto, pero es lo que deduzco :)** -> Eliminamos los puntos 81, 147 y 248. Vemos que el punto 65 no está includido, ésto es porqué:
  
  1. Mejor eliminar las menos observaciones posibles
  2. De los indicadores de puntos influyentes, los hat-values son los menos relevantes.

```{r}              
obs.rm <- c(81,147,248)                              # Eliminar las 2 mas influyentes a posteriori (81 y 147) y la peor explicada (248)
col.points <- rep(rgb(0,0,0,0.1),nrow(datos))        # Vector de colores
col.points[obs.rm] <- 2:4                            # Colores distintos para las observaciones influyentes
pairs(datos[,-10],col=col.points,pch=19,cex=0.8)     # Dibujo por pares de las observaciones influyentes
```

Éste plot nos muestra donde se encuentran los puntos influyentes seleccionados en los distintos gráficos que relacionan las características entre sí.

### 3. Ajuste del modelo sin observaciones influyentes

```{r}
datos.rm <- datos[-obs.rm ,]  # Nos creamos un nuevo data.frame sin estas observaciones
mod.lm7 <- lm(Strength~poly(Cement,2) + poly(BlastFurnaceSlag,2) + poly(FlyAsh,2)+
                       poly(Water,2) + poly(Superplasticizer,2)  +
                       poly(FineAggregate,2) + poly(Age,2),datos.rm)
```

### 4. Comparar con el Modelo 5

```{r}
summary(mod.lm7)   # Modelo nuevo sin outliers y observaciones influyentes
summary(mod.lm5)   # Modelo antiguo
```

Finalmente, es tan insignificante la mejora que obtenemos con el nuevo modelo (multiple R-squared 0.7857 en el nuevo vs 0.7798 en el antiguo) que nos quedamos con el antiguo. Menos transformaciones necesarias mejor.

## Modelo final: Modelo 5

```{r, fig.width=10, fig.height=10}
##-- Modelo final
mod.final <- mod.lm5

##-- Efectos
library('effects')
plot(allEffects(mod.final))
```

# Testear el modelo final con nuevos datos

## 1. Volver a hacer las transformaciones
```{r}
# setwd('...')
test <- read.table('Concrete_test.txt',sep="\t",header=TRUE)

##-- Volver a hacer transformaciones en test (por si la necesito)
test$Strength2 <- test$Strength^lamb
```

## 2. Predicciones para los nuevos valores

```{r}
##-- Predicciones
pr <- predict(mod.final,test)   # Predicciones para los nuevos valores
par(mfrow=c(1,1))           
plot(pr,test$Strength,asp=1)    # Predicciones vs valores predichos 
abline(0,1,col=2,lwd=2)         # Bisectriz
```

Valores reales vs valores predichos. Buen resultado, bastante ajustado.

## 3. Calculo del error y analizar resultados
```{r}
##--EQM (Error Cuadratico Medio)
n <- dim(test)[1]                                       # Tamanyo muestral
## vemos que es un 30% de la muestra de entrenamiento
EQM <- sum((pr-test$Strength)^2)/n                      # Error Cuadratico Medio
sqrt(EQM)                                               # Incertidumbre a posteriori                                                
```

Arriba: Incertidumbre a posteriori

```{r}
sd(test$Strength)                                       # Incertidumbre a priori --> El modelo me reduce a la mitad la incertidumbre en las predicciones
```

Arriba: Incertidumbre a priori, el modelo me reduce a la mitad la incertidumbre en las predicciones

```{r}
summary(test$Strength)
```

En un rango de 80, tener un error de 8 está bastante bien.