---
title: "MBD - Estadística - Práctica 1a (ML)"
author: Arturo Menchaca y Víctor Juez
date: Noviembre 22, 2020
output: 
  pdf_document:
    fig_caption: true
    number_sections: true
---

\newpage
\tableofcontents
\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE)
```

```{r}
rm(list = ls())

datos = read.table('../p1a_train.csv', header = TRUE, sep = ';', dec = '.', stringsAsFactors = TRUE)
datos$id = NULL

datos$year = factor(datos$year)
datos$season = factor(datos$season)
datos$holiday = factor(datos$holiday)
datos$workingday = factor(datos$workingday)
datos$weather = factor(datos$weather)
```

```{r}
#Indice
#------------------------
#- Analisis de variables
#  - Transformacion variable hora
#  - Descriptiva variables numericas (vemos correlacion temp y atemp)
#    - Analisis de temp y atemp (hacemos los modelos y elminamos el peor)
#    - Analisis de linealidad de las variables
#  - Variables categoricas (plots y resumen)
#- Generacion de modelos
#  - Modelo 1: Todas las variables (explicar resultado)
#  - Modelo 2: Seleccion automatica de variables
#    - Analisis de colinealidad (vif)
#    - Validacion de las premisas
#  - Transformacion de la variable resupesta
#    - Modelo 4: Transformacion Logaritmica (explicar resultado)
#    - Modelo 3: Transformacion BoxCox (imprimir solamente el modelo y explicar resultado, comparar con modelo anterior)
#      - Validacion (comparacion modelo anterior lm2)
#  - Modelo 5: Transformaciones polinomicas (imprimir y explicar solamente el resultado del modelo, vemos que no vale la pena)
#- Observaciones influyentes (imprimir influenceIndexPlot(mod.lm3))
#  - Modelo 6: Eliminar observaciones influyentes
#- Modelo final: el modelo 3 plot(alleffects)
#------------------------
```
# Conjunto de datos

El conjunto de datos consta de las siguientes variables:

- id: identificador de la franja horaria (no guarda relación con el orden temporal)
- year: año (2011 o 2012)
- hour: hora del día (0 a 23)
- season: 1 = invierno, 2 =primavera, 3 = verano, 4 = otoño
- holiday: si el día era festivo
- workingday: si el día era laborable (ni festivo ni fin de semana)
- weather: cuatro categorías (1 a 4) que van de mejor a peor tiempo
- temp: temperatura en grados celsius
- atemp: sensación de temperatura en grados celsius
- humidity: humedad relativa
- windspeed: velocidad del viento (km/h)
- count (sólo en el conjunto de entrenamiento): número total de alquileres en esa franja

A continuación mostramos la descriptiva de los datos:

```{r}
summary(datos)
```

# Análisis de las variables
## Categorización de la variable hora

Descriptiva de la variable respuesta en función de la variable hora:

```{r}
plot(count~hour, datos)
```

Decidimos agrupar la variable hora en los siguientes grupos:

- Morning: de 0:00h a 6:00h
- Moving: de 7:00h a 8:00h y de 17:00 a 19:00 
- Worktime: de 9:00h a 16:00h
- Night: de 20:00h a 23:00h

A continuación la descriptiva de la variable hora categorizada:

```{r}
datos$hourCategory = cut(datos$hour, c(0,6,8,16,19,23), labels = c('morning', 'moving', 'worktime', 'moving', 'night'), include.lowest = TRUE)
plot(count~hourCategory, datos)
datos$hour = NULL
```

## Descriptiva de las variables numéricas

```{r}
pairs(datos[, c(6:10)])
```

Como podemos observar en la descriptiva que mostramos a arriba, vemos que la variable temp y atemp estan muy relacionadas. Generamos un modelo utilizando cada una de las variables por separado para ver cual de las dos predice peor el resultado y eliminarla.

```{r}
datos$atemp = NULL
```

| |Modelo utilizando `temp`| Modelo utilizando `atemp`|
|---|---|---|
|R-squared|  0.1578 | 0.1537 |

`temp` describe mejor el resultado (R-squared mayor), eliminamos la variable `atemp`.

## Descriptiva de las variables categóricas

```{r}
par(mfrow=c(2,3))
for(i in c(1, 2, 3, 4, 5, 10)){
  boxplot(datos$count~datos[,i],main=names(datos)[i],xlab=names(datos)[i],ylab="count")
}
```

Vemos que a primera vista parece que algunas categorias van a influir más en la respuesta que otras. Las que tinen boxplots muy similares entre categorías menos representativas van a ser, como es el caso de `holiday` y `workingday`.

# Generación del modelo
## Modelo 1 - Utilizando todas las variables

```{r}
mod.lm1 = lm(count~.,datos)
```

- Variables utilizadas: `year`, `season`, `holiday`, `workingday`, `weather`, `temp`, `humidity`, `windspeed` y `hourCategory`.

| Propiedad | Valores |
|---|---|
|Residual standard error | 111.3 |
|Multiple R-squared | 0.6276 |
|p-value | < 2.2e-16 |

## Modelo 2 - Selección automática de variables

Hemos utilizado el método matemático AIC (Akaike Information Criterion) para determinar qué conjunto de variables es el óptimo para explicar el modelo y cualos sería conveniente eliminar. Recordemos que cuanto menor es el AIC mejor.

```{r results = FALSE}
mod.lm2 = step(mod.lm1)
datos$workingday = NULL
```

| Variable a eliminar | AIC eliminando la variable |
|---|---|
| `workingday` | 72472 |
| `<ninguna>` | 72473|
|`windspeed`| 72474|
|`holiday`| 72476 |
|`weather` | 72562 |
|`humidity` | 72664|
|`season` | 72862|
|`temp` |73040 |
|`year` | 73501|
|`hourCategory` | 77039|

Eliminamos la variable `workingday` y generamos otro modelo. A continuación el resultado.

| Propiedad | Valores |
|---|---|
|Residual standard error | 111.3 |
|Multiple R-squared | 0.6275 |
|p-value | < 2.2e-16 |

- Vemos un resultado prácticamente idéntico al del Modelo 1 pero utilizando una variable menos.

### Análisis de colinealidad de las variables
Utilizamos el indicador de VIF para analizar la colinealidad de las variables restantes por si tuviéramos que eliminar alguna más. Buscamos un valor de VIF < 5.

| Variable | VIF |
|---|---|
|year         | 1.025830 | 
|season       | 3.169114 | 
|holiday      | 1.003029 | 
|weather      | 1.292185 | 
|temp         | 3.083793 | 
|humidity     | 1.684752 | 
|windspeed    | 1.175091 | 
|hourCategory | 1.319474 | 

Podemos observar que el indicador VIF de todas las variables se mantiene por debajo del 5, lo que nos indica que hay poca colinealidad entre las variables y que no tendríamos que eliminar ninguna.

### Validación de las premisas

```{r}
par(mfrow=c(2,2))
plot(mod.lm2)
plot(resid(mod.lm2))
```

- **Homocedasticidad**: No se cumple, vemos que la dispersión de los residuos no es constante, forman una forma de embudo clara.
- **Linealidad**: Hay curvatura, tampoco se cumple.
- **Normalidad de los residuos**: Desviación de la distribución normal tanto en valores pequeños como en grandes, no se cumple.
- **Independencia**: Se cumple, vemos que la dispersión de los residuos a lo largo del orden en que aparecen en el conjunto de datos es constante.

## Modelo 3 - Transformación de la variable resupesta

```{r results = FALSE, fig.show='hide', messages = FALSE}
library(car)
bc <- boxCox(mod.lm2)
lamb = bc$x[which.max(bc$y)]
datos$countBC <- datos$count^lamb
```

Hemos generado dos nuevos modelos utilizando la transformación logarítmica y la de BoxCox de la variable respuesta. A continuación los resultados.

| |Transformación logarítmica| Transformación BoxCox|
|---|---|---|
|R-squared| 0.7184 | 0.7418 |
| Residual standard error | 0.7899 | 0.5919 |

- En general vemos una mejora sustancial utilizando una transformación en la variable respuesta, cualquiera de las dos.
- De las dos transformaciones, nos quedamos con la de BoxCox ya que nos da un mejor resultado.

# Modelo final - Modelo 3

- Variables utilizadas: `year, season, holiday, weather, temp, humidity, windspeed, hourCategory`
- Transformaciones:
  - BoxCox en la variable respuesta
  - Categorización de la variable hora
- Resultado:
  
  |Propiedes|Valores|
  |---|---|---|
  | Residual standard error | 0.5919 |
  | Multiple R-squared | 0.7418 |
  | p-value | < 2.2e-16 |

- Expresión del modelo

```{r}
mod.lm3 = lm(countBC ~ year + season + holiday + weather + temp + humidity + windspeed + hourCategory, datos)
summary(mod.lm3)
```

## Validación del modelo

```{r}
mod.lm3 = lm(countBC ~ year + season + holiday + weather + temp + humidity + windspeed + hourCategory, datos)
par(mfrow=c(2,2))
plot(mod.lm3)
plot(resid(mod.lm3))
```

- **Homocedasticidad**: Se cumple, sigue habiendo más dispersión en el centro y en valores más altos que en pequeños, pero ya no tenemos la forma de embudo tan destacada que teníamos en el Modelo 2.
- **Linealidad**: Se cumple, hay curvatura pero muy leve.
- **Normalidad de los residuos**: Sigue desviándose en valores altos pero podríamos considerar que ahora se cumple, ha mejorado respecto al Modelo 2.
- **Independencia**: Se cumple, igual que en el Modelo 2.

## Efecto de las características sobre la variable respuesta

```{r messages = FALSE, results = FALSE, fig.width=10, fig.height=10}
library('effects')
plot(allEffects(mod.lm3))
```

\newpage

# Anexos - Modelos descartados

## Modelo 4: Transformación polinómica
Hemos realizado una transformación polinómica a las variables numéricas y generado un nuevo modelo con ellas. Vemos el resultado a continuación.

- Modelo de referencia: Modelo 3
- Transformación añadida: Transformación polinómica de las variables `temp`, `humidity` y `windspeed`
- Resultado:
  
  |Propiedes|Valores|
  |---|---|
  | Residual standard error | 0.5884 |
  | Multiple R-squared | 0.7449 |
  | p-value | < 2.2e-16 |

-  Vemos que hay una diferencia insignificante respecto al Modelo 3, por lo que no vemos que sea necesario utilizar la transformación polinómica

## Modelo 5: Eliminar observaciones influyentes
Analizamos las observaciones influyentes del Modelo 3:

```{r}
influenceIndexPlot(mod.lm3)
```

Vemos que las observaciones 2005 y 6737 son las que tienen una distancia de Cook mayor, por lo que son las más influyentes. A continuación sus distancias de Cook respectivas:

|Observación|Distancia de Cook|
|---|---|
| 2005 | 0.0050 |
| 6737 | 0.0052 |

Eliminamos estas dos observaciones y generamos un nuevo modelo.

- Modelo de referencia: Modelo 3
- Transformación añadida: Eliminación de las observaciones influyentes 2005 y 6737
- Resultado:
  
  |Propiedes|Valores|
  |---|---|
  | Residual standard error | 0.5911 |
  | Multiple R-squared | 0.7425 |
  | p-value | < 2.2e-16 |

-  De nuevo, la diferencia es insignificante respecto el Modelo 3, por lo que no interesa hacer esta transformación

